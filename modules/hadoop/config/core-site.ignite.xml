<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<!--
  Licensed to the Apache Software Foundation (ASF) under one or more
  contributor license agreements.  See the NOTICE file distributed with
  this work for additional information regarding copyright ownership.
  The ASF licenses this file to You under the Apache License, Version 2.0
  (the "License"); you may not use this file except in compliance with
  the License.  You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License.
-->

<!--
    This template file contains settings needed to run Apache Hadoop jobs
    with Apache Ignite's distributed in-memory file system IGFS.

    You can replace '$HADOOP_HOME/etc/hadoop/core-site.xml' file with this one
    to work with IGFS nodes running on localhost (these local nodes can be
    a part of distributed cluster though). To work with file system on remote
    hosts you need to change the host of file system URI to any host running
    IGFS node.

    Note that Ignite jars must be in Apache Hadoop client classpath to work
    with this configuration.

    Run script '$IGNITE_HOME/bin/setup-hadoop.{sh|bat}' for Apache Hadoop client setup.
-->

<configuration>
    <!--
        Set default file system to IGFS instance named "igfs" configured in Ignite.
    -->
    <property>
        <name>fs.default.name</name>
        <value>igfs://igfs@localhost</value>
    </property>

    <!--
        Set Hadoop 1.* file system implementation class for IGFS.
    -->
    <property>
        <name>fs.igfs.impl</name>
        <value>org.apache.ignite.hadoop.fs.v1.IgniteHadoopFileSystem</value>
    </property>

    <!--
        Set Hadoop 2.* file system implementation class for IGFS.
    -->
    <property>
        <name>fs.AbstractFileSystem.igfs.impl</name>
        <value>org.apache.ignite.hadoop.fs.v2.IgniteHadoopFileSystem</value>
    </property>

    <!--
        Disallow data node replacement since it does not make sense for IGFS nodes.
    -->
    <property>
        <name>dfs.client.block.write.replace-datanode-on-failure.policy</name>
        <value>NEVER</value>
    </property>

    <!--
        Allow to write the job statistics into IGFS.
    -->
    <!--
    <property>
        <name>ignite.counters.writer</name>
        <value>org.apache.ignite.hadoop.fs.IgniteHadoopFileSystemCounterWriter</value>
    </property>
    -->

    <!--
        By default data is placed into the file /user/<user_name>/<job_id>/performance
        You can override this path with using macro ${USER} that is to injection of submitter user name.
    -->
    <!--
    <property>
        <name>ignite.counters.fswriter.directory</name>
        <value>/user/${USER}</value>
    </property>
    -->
</configuration>
